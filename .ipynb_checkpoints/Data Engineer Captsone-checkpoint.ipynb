{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project 6 - Data Engineering Capstone Project\n",
    "## Immigration, demographic and travel analysis\n",
    "\n",
    "### Overview\n",
    "The purpose of the data engineering capstone project is to give you a chance to combine what you've learned throughout the program. This project will be an important part of your portfolio that will help you achieve your data engineering-related career goals.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "#### Step 1: Scope the Project and Gather Data\n",
    "Since the scope of the project will be highly dependent on the data, these two things happen simultaneously. In this step, youâ€™ll:\n",
    "\n",
    "* Identify and gather the data you'll be using for your project (at least two sources and more than 1 million rows). See Project Resources for ideas of what data you can use.\n",
    "\n",
    "* Explain what end use cases you'd like to prepare the data for (e.g., analytics table, app back-end, source-of-truth database, etc.)\n",
    "\n",
    "#### Step 2: Explore and Assess the Data\n",
    "* Explore the data to identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "* Document steps necessary to clean the data\n",
    "\n",
    "#### Step 3: Define the Data Model\n",
    "* Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "* List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "#### Step 4: Run ETL to Model the Data\n",
    "* Create the data pipelines and the data model\n",
    "\n",
    "* Include a data dictionary\n",
    "\n",
    "* Run data quality checks to ensure the pipeline ran as expected\n",
    "\n",
    "    * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    "\n",
    "    * Unit tests for the scripts to ensure they are doing the right thing\n",
    "\n",
    "    * Source/count checks to ensure completeness\n",
    "\n",
    "#### Step 5: Complete Project Write Up\n",
    "* What's the goal? What queries will you want to run? How would Spark or Airflow be incorporated? Why did you choose the model you chose?\n",
    "\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "* Document the steps of the process.\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "\n",
    "* Post your write-up and final data model in a GitHub repo.\n",
    "\n",
    "* Include a description of how you would approach the problem differently under the following scenarios:\n",
    "\n",
    "    * If the data was increased by 100x.\n",
    "\n",
    "    * If the pipelines were run on a daily basis by 7am.\n",
    "\n",
    "    * If the database needed to be accessed by 100+ people.\n",
    "\n",
    "#### Rubric\n",
    "In the [Project Rubric](https://review.udacity.com/#!/rubrics/2497/view), you'll see more detail about the requirements. Use the rubric to assess your own project before you submit to Udacity for review. As with other projects, Udacity reviewers will use this rubric to assess your project and provide feedback. If your project does not meet specifications, you can make changes and resubmit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, date_add, to_date, expr\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, dayofweek\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "This project aims to combine immigration, weather, demographic and airport data in order to derive some insights.\n",
    "We work as a data engineer in a travel agency that wants to know, for example, to which US states people from different\n",
    "countries and ages travel, what type of weather they prefer and demographics for each visited city. With this information, the agency\n",
    "hopes to get a better idea about which travel packages to offer to which customers, for example, in order to maximize sales potential.\n",
    "\n",
    "#### Datasets\n",
    "The following datasets are used:\n",
    "\n",
    "- __I94 Immigration Data__: This data comes from the US National Tourism and Trade Office. A data dictionary is included in the workspace. [This](https://travel.trade.gov/research/reports/i94/historical/2016.html) is where the data comes from. There's a sample file so you can take a look at the data in csv format before reading it all in. You do not have to use the entire dataset, just use what you need to accomplish the goal you set at the beginning of the project.\n",
    "- __World Temperature Data__: This dataset came from Kaggle. You can read more about it [here](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data).\n",
    "- __U.S. City Demographic Data__: This data comes from OpenSoft. You can read more about it [here](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/).\n",
    "- __Airport Code Table__: This is a simple table of airport codes and corresponding cities. It comes from [here](https://datahub.io/core/airport-codes#data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "\n",
    "To explore the data, pandas was used because it is easy to use and visualize data, and since we are just exploring and cleanning, and not doing heavy transformations, it is appropriate.\n",
    "\n",
    "#### Cleaning Steps\n",
    "\n",
    "For each of the datasets used, we check the columns for missing values, drop unnecessary columns and duplicates, and split columns when necessary to make data access easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Cleanning state weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>average_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>17.066138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>-4.890738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>15.381526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>15.573963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>14.327677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  average_temperature\n",
       "0     Alabama            17.066138\n",
       "1      Alaska            -4.890738\n",
       "2     Arizona            15.381526\n",
       "3    Arkansas            15.573963\n",
       "4  California            14.327677"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring and cleanning airport data\n",
    "state_weather = pd.read_csv('data/temperature_by_state.csv', sep=',')\n",
    "\n",
    "# Droping NA entries\n",
    "state_weather.dropna(inplace=True)\n",
    "\n",
    "# Dropping columns that will not be used\n",
    "state_weather.drop(['dt'], axis=1, inplace=True)\n",
    "state_weather.drop(['AverageTemperatureUncertainty'], axis=1, inplace=True)\n",
    "\n",
    "# Selecting only US states and dropping Country column\n",
    "state_weather = state_weather[state_weather['Country'] == 'United States']\n",
    "state_weather.drop(['Country'], axis=1, inplace=True)\n",
    "\n",
    "# Renaming columns\n",
    "state_weather_columns = {\n",
    "    'AverageTemperature': 'average_temperature',\n",
    "    'State': 'state'\n",
    "}\n",
    "state_weather.rename(columns=state_weather_columns, inplace=True)\n",
    "\n",
    "# Grouping by state and getting temperature average\n",
    "state_weather = state_weather.groupby(['state'])['average_temperature'].mean().reset_index()\n",
    "\n",
    "state_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Cleanning country weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>average_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>14.045007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa</td>\n",
       "      <td>24.074203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>12.610646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>22.985112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>26.611965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  average_temperature\n",
       "0     Afghanistan            14.045007\n",
       "1          Africa            24.074203\n",
       "2         Albania            12.610646\n",
       "3         Algeria            22.985112\n",
       "4  American Samoa            26.611965"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring and cleanning airport data\n",
    "country_weather = pd.read_csv('data/temperature_by_country.csv', sep=',')\n",
    "\n",
    "# Droping NA entries\n",
    "country_weather.dropna(inplace=True)\n",
    "\n",
    "# Dropping columns that will not be used\n",
    "country_weather.drop(['dt'], axis=1, inplace=True)\n",
    "country_weather.drop(['AverageTemperatureUncertainty'], axis=1, inplace=True)\n",
    "\n",
    "# Renaming columns\n",
    "country_weather_columns = {\n",
    "    'AverageTemperature': 'average_temperature',\n",
    "    'Country': 'country'\n",
    "}\n",
    "country_weather.rename(columns=country_weather_columns, inplace=True)\n",
    "\n",
    "# Grouping by state and getting temperature average\n",
    "country_weather = country_weather.groupby(['country'])['average_temperature'].mean().reset_index()\n",
    "\n",
    "country_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Cleanning airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>continent</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ocean Reef Club Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Key Largo</td>\n",
       "      <td>OCA</td>\n",
       "      <td>-80.274803</td>\n",
       "      <td>25.325399</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pilot Station Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Pilot Station</td>\n",
       "      <td>PQS</td>\n",
       "      <td>-162.899994</td>\n",
       "      <td>61.934601</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crested Butte Airpark</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Crested Butte</td>\n",
       "      <td>CSE</td>\n",
       "      <td>-106.928341</td>\n",
       "      <td>38.851918</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LBJ Ranch Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Johnson City</td>\n",
       "      <td>JCY</td>\n",
       "      <td>-98.622498</td>\n",
       "      <td>30.251801</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Metropolitan Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Palmer</td>\n",
       "      <td>PMX</td>\n",
       "      <td>-72.311401</td>\n",
       "      <td>42.223301</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name continent country           city iata_code  \\\n",
       "0  Ocean Reef Club Airport        NA      US      Key Largo       OCA   \n",
       "1    Pilot Station Airport        NA      US  Pilot Station       PQS   \n",
       "2    Crested Butte Airpark        NA      US  Crested Butte       CSE   \n",
       "3        LBJ Ranch Airport        NA      US   Johnson City       JCY   \n",
       "4     Metropolitan Airport        NA      US         Palmer       PMX   \n",
       "\n",
       "    longitude   latitude state  \n",
       "0  -80.274803  25.325399    FL  \n",
       "1 -162.899994  61.934601    AK  \n",
       "2 -106.928341  38.851918    CO  \n",
       "3  -98.622498  30.251801    TX  \n",
       "4  -72.311401  42.223301    MA  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring and cleanning airport data\n",
    "airports = pd.read_csv('data/airport-codes_csv.csv', sep=',', keep_default_na=False, na_values=[''])\n",
    "\n",
    "# Checking if ident is present in all rows\n",
    "airports.ident.count() == airports.shape[0]\n",
    "\n",
    "# Select only US airports\n",
    "airports = airports[airports['iso_country'] == 'US']\n",
    "\n",
    "# Spliting coordinates into longitude and latitude\n",
    "airports['longitude'], airports['latitude'] = airports['coordinates'].str.split(',', 1).str\n",
    "airports[['longitude', 'latitude']] = airports[['longitude', 'latitude']].astype(float)\n",
    "\n",
    "# Spliting iso_region and creating state column\n",
    "_, airports['state'] = airports['iso_region'].str.split('-', 1).str\n",
    "\n",
    "# Drop airports without IATA_CODE\n",
    "airports.dropna(subset=['iata_code'], inplace=True)\n",
    "\n",
    "# Checking if IATA_CODEs are unique\n",
    "airports.iata_code.count() == airports.shape[0]\n",
    "\n",
    "# Dropping columns that will not be used\n",
    "unused_columns = ['ident', 'type', 'elevation_ft', 'iso_region', 'gps_code', 'local_code', 'coordinates']\n",
    "airports.drop(unused_columns, axis=1, inplace=True)\n",
    "\n",
    "# Resetting indexes\n",
    "airports.reset_index(inplace=True)\n",
    "airports.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "# Dropping duplicates\n",
    "airports.drop_duplicates(inplace=True)\n",
    "\n",
    "# Renamming iso_country column\n",
    "airports.rename(columns={'iso_country': 'country', 'municipality': 'city'}, inplace=True)\n",
    "\n",
    "airports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Cleaning cities demographics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>state_code</th>\n",
       "      <th>race</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>30908</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>32935</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>8229</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>33878</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>86253</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city          state  median_age  male_population  \\\n",
       "0     Silver Spring       Maryland        33.8            40601   \n",
       "1            Quincy  Massachusetts        41.0            44129   \n",
       "2            Hoover        Alabama        38.5            38040   \n",
       "3  Rancho Cucamonga     California        34.5            88127   \n",
       "4            Newark     New Jersey        34.6           138040   \n",
       "\n",
       "   female_population  total_population  foreign_born state_code  \\\n",
       "0              41862             82463         30908         MD   \n",
       "1              49500             93629         32935         MA   \n",
       "2              46799             84839          8229         AL   \n",
       "3              87105            175232         33878         CA   \n",
       "4             143873            281913         86253         NJ   \n",
       "\n",
       "                        race  count  \n",
       "0         Hispanic or Latino  25924  \n",
       "1                      White  58723  \n",
       "2                      Asian   4759  \n",
       "3  Black or African-American  24437  \n",
       "4                      White  76402  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring and cleaning demographics data\n",
    "cities_demographics = pd.read_csv('data/us-cities-demographics.csv', sep=';')\n",
    "\n",
    "# Dropping NA and duplicates\n",
    "cities_demographics.dropna(inplace=True)\n",
    "cities_demographics.drop_duplicates(inplace=True)\n",
    "\n",
    "# Renaming columns for convention\n",
    "demographics_columns = {\n",
    "    'City': 'city',\n",
    "    'State': 'state',\n",
    "    'Median Age': 'median_age',\n",
    "    'Male Population': 'male_population',\n",
    "    'Female Population': 'female_population',\n",
    "    'Total Population': 'total_population',\n",
    "    'Number of Veterans': 'number_of_veterans',\n",
    "    'Foreign-born': 'foreign_born',\n",
    "    'Average Household Size': 'average_household_size',\n",
    "    'State Code': 'state_code',\n",
    "    'Race': \"race\",\n",
    "    'Count': \"count\"\n",
    "}\n",
    "cities_demographics.rename(columns=demographics_columns, inplace=True)\n",
    "\n",
    "# Dropping unused columns\n",
    "unused_columns = ['number_of_veterans', 'average_household_size']\n",
    "cities_demographics.drop(unused_columns, axis=1, inplace=True)\n",
    "\n",
    "# Dropping duplicates\n",
    "immigration_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Casting column types\n",
    "cities_demographics['male_population'] = cities_demographics['male_population'].astype(int)\n",
    "cities_demographics['female_population'] = cities_demographics['female_population'].astype(int)\n",
    "cities_demographics['foreign_born'] = cities_demographics['foreign_born'].astype(int)\n",
    "\n",
    "cities_demographics.race.unique()\n",
    "cities_demographics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Cleaning immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citizenship_country</th>\n",
       "      <th>residence_country</th>\n",
       "      <th>airport_code</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>travel_mode</th>\n",
       "      <th>state</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>passenger_age</th>\n",
       "      <th>visa_purpose</th>\n",
       "      <th>passenger_birthyear</th>\n",
       "      <th>gender</th>\n",
       "      <th>vita_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>209</td>\n",
       "      <td>209</td>\n",
       "      <td>HHW</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>1955</td>\n",
       "      <td>F</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "      <td>MCA</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>1990</td>\n",
       "      <td>M</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148</td>\n",
       "      <td>112</td>\n",
       "      <td>OGG</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>1940</td>\n",
       "      <td>M</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297</td>\n",
       "      <td>297</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-07</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1991</td>\n",
       "      <td>M</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>CHM</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>1997</td>\n",
       "      <td>F</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   citizenship_country  residence_country airport_code arrival_date  \\\n",
       "0                  209                209          HHW   2016-04-22   \n",
       "1                  582                582          MCA   2016-04-23   \n",
       "2                  148                112          OGG   2016-04-07   \n",
       "3                  297                297          LOS   2016-04-28   \n",
       "4                  111                111          CHM   2016-04-06   \n",
       "\n",
       "   travel_mode state departure_date  passenger_age  visa_purpose  \\\n",
       "0          1.0    HI     2016-04-29             61             2   \n",
       "1          1.0    TX     2016-04-24             26             2   \n",
       "2          1.0    FL     2016-04-27             76             2   \n",
       "3          1.0    CA     2016-05-07             25             2   \n",
       "4          3.0    NY     2016-04-09             19             2   \n",
       "\n",
       "   passenger_birthyear gender vita_type  \n",
       "0                 1955      F        WT  \n",
       "1                 1990      M        B2  \n",
       "2                 1940      M        WT  \n",
       "3                 1991      M        B2  \n",
       "4                 1997      F        WT  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "immigration_data = pd.read_csv('immigration_data_sample.csv', sep=',')\n",
    "\n",
    "# Droppinig unused columns\n",
    "unused_columns = [0, 1, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27]\n",
    "immigration_data.drop(immigration_data.columns[unused_columns], axis=1, inplace=True)\n",
    "\n",
    "# Renaming columns\n",
    "immigration_columns = {\n",
    "    \"i94yr\": \"year\",\n",
    "    \"i94mon\": \"month\",\n",
    "    \"i94cit\": \"citizenship_country\",\n",
    "    \"i94res\": \"residence_country\",\n",
    "    \"i94port\": \"airport_code\",\n",
    "    \"arrdate\": \"arrival_date\",\n",
    "    \"i94mode\": \"travel_mode\",\n",
    "    \"i94addr\": \"state\",\n",
    "    \"depdate\": \"departure_date\",\n",
    "    \"i94visa\": \"visa_purpose\",\n",
    "    \"i94bir\": \"passenger_age\",\n",
    "    \"biryear\": \"passenger_birthyear\",\n",
    "    \"visatype\": \"vita_type\"\n",
    "}\n",
    "immigration_data.rename(columns=immigration_columns, inplace=True)\n",
    "\n",
    "# Dropping NA and duplicates\n",
    "immigration_data.dropna(inplace=True)\n",
    "immigration_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Casting columns to correct types\n",
    "immigration_data['citizenship_country'] = immigration_data['citizenship_country'].astype(int)\n",
    "immigration_data['residence_country'] = immigration_data['residence_country'].astype(int)\n",
    "immigration_data['year'] = immigration_data['year'].astype(int)\n",
    "immigration_data['month'] = immigration_data['month'].astype(int)\n",
    "immigration_data['passenger_age'] = immigration_data['passenger_age'].astype(int)\n",
    "immigration_data['visa_purpose'] = immigration_data['visa_purpose'].astype(int)\n",
    "immigration_data['passenger_birthyear'] = immigration_data['passenger_birthyear'].astype(int)\n",
    "\n",
    "# Casting arrival_date and departure_date to date type\n",
    "immigration_data['arrival_date'] = pd.to_datetime(\"1960-01-01\") + pd.to_timedelta(immigration_data['arrival_date'], unit='d')\n",
    "immigration_data['departure_date'] = pd.to_datetime(\"1960-01-01\") + pd.to_timedelta(immigration_data['departure_date'], unit='d')\n",
    "\n",
    "# Dropping year and month column since they can be derived from arrival date\n",
    "immigration_data.drop(['year', 'month'], axis=1, inplace=True)\n",
    "\n",
    "immigration_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Cleanning country data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>Andorra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country_code country_name\n",
       "0           582       Mexico\n",
       "1           236  Afghanistan\n",
       "2           101      Albania\n",
       "3           316      Algeria\n",
       "4           102      Andorra"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_data = pd.read_csv('data/country_codes.csv', sep='=')\n",
    "\n",
    "# Removing single quotes from country names\n",
    "country_data['country_name'] = country_data['country_name'].str.replace('\\'', '')\n",
    "\n",
    "# Trimming whitespace\n",
    "country_data['country_name'] = country_data['country_name'].str.strip()\n",
    "\n",
    "# Capitalize only first letters of country names\n",
    "country_data['country_name'] = country_data['country_name'].str.title()\n",
    "\n",
    "country_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Cleanning state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>state_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code  state_name\n",
       "0         AL     Alabama\n",
       "1         AK      Alaska\n",
       "2         AZ     Arizona\n",
       "3         AR    Arkansas\n",
       "4         CA  California"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_data = pd.read_csv('data/state_codes.csv', sep='=')\n",
    "\n",
    "# Removing single quotes from state_codes and state_names\n",
    "state_data['state_code'] = state_data['state_code'].str.replace('\\'', '')\n",
    "state_data['state_name'] = state_data['state_name'].str.replace('\\'', '')\n",
    "\n",
    "# Capitalize only first letters of state names\n",
    "state_data['state_name'] = state_data['state_name'].str.title()\n",
    "\n",
    "state_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Loading additional mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visa_code</th>\n",
       "      <th>visa_purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visa_code visa_purpose\n",
       "0          1     Business\n",
       "1          2     Pleasure\n",
       "2          3      Student"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visa_purposes = pd.read_csv('data/visa_purposes.csv', sep='=')\n",
    "travel_modes = pd.read_csv('data/travel_modes.csv', sep='=')\n",
    "\n",
    "visa_purposes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "\n",
    "No matching between airport and immigration data set was found. The IATA_CODEs don't correspond to the airport code of the immigration data, so airports data will not be used, since there is no fail-safe way of linking both data sources. State could be used, but is too broad to identify an airport.\n",
    "\n",
    "#### 3.1 Conceptual Data Model\n",
    "A star schema will be used because it is very easy to query analytics and aggregate data to anwser business questions with it.\n",
    "Dimension tables for country, state and times will be created.\n",
    "Our facts table will be based on immigration data from the immigration dataset. A picture of our schema follows.\n",
    "\n",
    "![](db_diagram.png)\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "Spark will be used to aggregate data and create our data model. We move from Pandas because now we are not exploring subsets of data anymore. Now we will work with a huge volume of data and Spark allows us to scale it and paralelize processing if required.\n",
    "\n",
    "The state table will contain demographics data that will be obtained by aggregating the cities demographics dataset. It will also contain weather information.\n",
    "\n",
    "The country table will contain weather information and country codes obtained from the immigration dataset.\n",
    "\n",
    "The times table will be built based on dates contained in the immigration data.\n",
    "\n",
    "To create our facts table, we will use the immigration data and some mappings for state, country and visa purpose codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Creating spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "    .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Importing and cleanning full immigration data on spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citizenship_country</th>\n",
       "      <th>residence_country</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>travel_mode</th>\n",
       "      <th>state</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>passenger_age</th>\n",
       "      <th>visa_purpose</th>\n",
       "      <th>passenger_birthyear</th>\n",
       "      <th>gender</th>\n",
       "      <th>visa_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>IN</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1974</td>\n",
       "      <td>F</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>PR</td>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1956</td>\n",
       "      <td>M</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>112</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>1964</td>\n",
       "      <td>M</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>NJ</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>1967</td>\n",
       "      <td>M</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1976</td>\n",
       "      <td>M</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>1954</td>\n",
       "      <td>F</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>1945</td>\n",
       "      <td>M</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1978</td>\n",
       "      <td>M</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1992</td>\n",
       "      <td>F</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1969</td>\n",
       "      <td>F</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   citizenship_country  residence_country arrival_date  travel_mode state  \\\n",
       "0                  103                103   2016-04-01            1    IN   \n",
       "1                  103                103   2016-04-01            1    PR   \n",
       "2                  103                112   2016-04-01            1    FL   \n",
       "3                  104                104   2016-04-01            1    NJ   \n",
       "4                  104                104   2016-04-01            1    NY   \n",
       "5                  104                104   2016-04-01            1    NY   \n",
       "6                  104                104   2016-04-01            1    CA   \n",
       "7                  104                104   2016-04-01            1    NV   \n",
       "8                  104                104   2016-04-01            1    FL   \n",
       "9                  104                104   2016-04-01            1    FL   \n",
       "\n",
       "  departure_date  passenger_age  visa_purpose  passenger_birthyear gender  \\\n",
       "0     2016-04-07             42             1                 1974      F   \n",
       "1     2016-04-16             60             2                 1956      M   \n",
       "2     2016-04-15             52             2                 1964      M   \n",
       "3     2016-04-08             49             2                 1967      M   \n",
       "4     2016-04-10             40             2                 1976      M   \n",
       "5     2016-04-17             62             2                 1954      F   \n",
       "6     2016-04-29             71             2                 1945      M   \n",
       "7     2016-04-09             38             2                 1978      M   \n",
       "8     2016-04-10             24             2                 1992      F   \n",
       "9     2016-04-08             47             2                 1969      F   \n",
       "\n",
       "  visa_type  \n",
       "0        WB  \n",
       "1        WT  \n",
       "2        WT  \n",
       "3        WT  \n",
       "4        WT  \n",
       "5        WT  \n",
       "6        WT  \n",
       "7        WT  \n",
       "8        WT  \n",
       "9        WT  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_data_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "# immigration_data_spark = spark.read.csv('immigration_data_sample.csv')\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "drop_columns = ['cicid', 'i94yr', 'i94mon', 'i94port', 'entdepu', 'matflag', 'airline', 'admnum', \\\n",
    "                'fltno', 'occup', 'entdepg', 'insnum', 'dtaddto', 'entdepd', 'count', 'dtadfile', \\\n",
    "                'entdepa', 'visapost']\n",
    "immigration_data_spark = immigration_data_spark.drop(*drop_columns)\n",
    "\n",
    "# Renaming columns\n",
    "immigration_data_spark = immigration_data_spark.withColumnRenamed('i94cit', 'citizenship_country')\n",
    "immigration_data_spark = immigration_data_spark.withColumnRenamed('i94res', 'residence_country')\n",
    "immigration_data_spark = immigration_data_spark.withColumnRenamed('i94port', 'airport_code')\n",
    "immigration_data_spark = immigration_data_spark.withColumnRenamed('arrdate', 'arrival_date')\n",
    "immigration_data_spark = immigration_data_spark.withColumnRenamed('i94mode', 'travel_mode')\n",
    "immigration_data_spark = immigration_data_spark.withColumnRenamed('i94addr', 'state')\n",
    "immigration_data_spark = immigration_data_spark.withColumnRenamed('depdate', 'departure_date')\n",
    "immigration_data_spark = immigration_data_spark.withColumnRenamed('i94visa', 'visa_purpose')\n",
    "immigration_data_spark = immigration_data_spark.withColumnRenamed('i94bir', 'passenger_age')\n",
    "immigration_data_spark = immigration_data_spark.withColumnRenamed('biryear', 'passenger_birthyear')\n",
    "immigration_data_spark = immigration_data_spark.withColumnRenamed('visatype', 'visa_type')\n",
    "\n",
    "# Cleanning data\n",
    "immigration_data_spark = immigration_data_spark.dropna()\n",
    "immigration_data_spark = immigration_data_spark.distinct()\n",
    "\n",
    "# Processing dates columns\n",
    "immigration_data_spark = immigration_data_spark.withColumn('arrival_date', expr(\"date_add(to_date('1960-01-01'), arrival_date)\"))\n",
    "immigration_data_spark = immigration_data_spark.withColumn('departure_date', expr(\"date_add(to_date('1960-01-01'), departure_date)\"))\n",
    "\n",
    "# Casting data to correct type\n",
    "immigration_data_spark = immigration_data_spark.withColumn('citizenship_country', immigration_data_spark.citizenship_country.cast('int'))\n",
    "immigration_data_spark = immigration_data_spark.withColumn('residence_country', immigration_data_spark.residence_country.cast('int'))\n",
    "immigration_data_spark = immigration_data_spark.withColumn('travel_mode', immigration_data_spark.travel_mode.cast('int'))\n",
    "immigration_data_spark = immigration_data_spark.withColumn('passenger_age', immigration_data_spark.passenger_age.cast('int'))\n",
    "immigration_data_spark = immigration_data_spark.withColumn('visa_purpose', immigration_data_spark.visa_purpose.cast('int'))\n",
    "immigration_data_spark = immigration_data_spark.withColumn('passenger_birthyear', immigration_data_spark.passenger_birthyear.cast('int'))\n",
    "\n",
    "immigration_data_spark.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Getting cleanned pandas df as spark df and registering them as tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "state_weather_spark = spark.createDataFrame(state_weather)\n",
    "country_weather_spark = spark.createDataFrame(country_weather)\n",
    "state_data_spark = spark.createDataFrame(state_data)\n",
    "country_data_spark = spark.createDataFrame(country_data)\n",
    "cities_demographics_spark = spark.createDataFrame(cities_demographics)\n",
    "travel_modes_spark = spark.createDataFrame(travel_modes)\n",
    "visa_purposes_spark = spark.createDataFrame(visa_purposes)\n",
    "\n",
    "state_weather_spark.createOrReplaceTempView(\"state_weather\")\n",
    "country_weather_spark.createOrReplaceTempView(\"country_weather\")\n",
    "state_data_spark.createOrReplaceTempView(\"state_data\")\n",
    "country_data_spark.createOrReplaceTempView(\"country_data\")\n",
    "cities_demographics_spark.createOrReplaceTempView(\"cities_demographics\")\n",
    "immigration_data_spark.createOrReplaceTempView(\"immigration_data\")\n",
    "travel_modes_spark.createOrReplaceTempView(\"travel_modes\")\n",
    "visa_purposes_spark.createOrReplaceTempView(\"visa_purposes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Creating dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>state</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>hispanic_or_latino</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>black_or_african_american</th>\n",
       "      <th>american_indian_and_alaska_native</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UT</td>\n",
       "      <td>Utah</td>\n",
       "      <td>8.478841</td>\n",
       "      <td>517350</td>\n",
       "      <td>506585</td>\n",
       "      <td>1023935</td>\n",
       "      <td>130362</td>\n",
       "      <td>201695</td>\n",
       "      <td>889798</td>\n",
       "      <td>48801</td>\n",
       "      <td>21893</td>\n",
       "      <td>18746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HI</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>22.439283</td>\n",
       "      <td>176807</td>\n",
       "      <td>175959</td>\n",
       "      <td>352766</td>\n",
       "      <td>101312</td>\n",
       "      <td>24586</td>\n",
       "      <td>110508</td>\n",
       "      <td>240978</td>\n",
       "      <td>11781</td>\n",
       "      <td>5592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MN</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>4.472812</td>\n",
       "      <td>695760</td>\n",
       "      <td>713072</td>\n",
       "      <td>1408833</td>\n",
       "      <td>213977</td>\n",
       "      <td>103229</td>\n",
       "      <td>1050239</td>\n",
       "      <td>151544</td>\n",
       "      <td>216731</td>\n",
       "      <td>25242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>10.320152</td>\n",
       "      <td>1170650</td>\n",
       "      <td>1248659</td>\n",
       "      <td>2419310</td>\n",
       "      <td>174778</td>\n",
       "      <td>164686</td>\n",
       "      <td>1491755</td>\n",
       "      <td>86006</td>\n",
       "      <td>877366</td>\n",
       "      <td>31808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>15.573963</td>\n",
       "      <td>280144</td>\n",
       "      <td>296433</td>\n",
       "      <td>576577</td>\n",
       "      <td>61550</td>\n",
       "      <td>77813</td>\n",
       "      <td>384733</td>\n",
       "      <td>22062</td>\n",
       "      <td>149608</td>\n",
       "      <td>9381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OR</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>8.165825</td>\n",
       "      <td>707443</td>\n",
       "      <td>729066</td>\n",
       "      <td>1436509</td>\n",
       "      <td>185753</td>\n",
       "      <td>201498</td>\n",
       "      <td>1235819</td>\n",
       "      <td>117279</td>\n",
       "      <td>72150</td>\n",
       "      <td>38597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>18.107234</td>\n",
       "      <td>6972438</td>\n",
       "      <td>7138331</td>\n",
       "      <td>14110770</td>\n",
       "      <td>2899610</td>\n",
       "      <td>6311431</td>\n",
       "      <td>10508923</td>\n",
       "      <td>924552</td>\n",
       "      <td>2130242</td>\n",
       "      <td>154497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ND</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>4.169715</td>\n",
       "      <td>95235</td>\n",
       "      <td>94255</td>\n",
       "      <td>189490</td>\n",
       "      <td>11492</td>\n",
       "      <td>5234</td>\n",
       "      <td>172068</td>\n",
       "      <td>5576</td>\n",
       "      <td>8177</td>\n",
       "      <td>7142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PA</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>9.110052</td>\n",
       "      <td>1102940</td>\n",
       "      <td>1197619</td>\n",
       "      <td>2300560</td>\n",
       "      <td>287987</td>\n",
       "      <td>387081</td>\n",
       "      <td>1245618</td>\n",
       "      <td>159308</td>\n",
       "      <td>851200</td>\n",
       "      <td>31849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CT</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>9.020080</td>\n",
       "      <td>424687</td>\n",
       "      <td>446332</td>\n",
       "      <td>871019</td>\n",
       "      <td>222850</td>\n",
       "      <td>309992</td>\n",
       "      <td>505674</td>\n",
       "      <td>48311</td>\n",
       "      <td>231822</td>\n",
       "      <td>10729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code         state  average_temperature  male_population  \\\n",
       "0         UT          Utah             8.478841           517350   \n",
       "1         HI        Hawaii            22.439283           176807   \n",
       "2         MN     Minnesota             4.472812           695760   \n",
       "3         OH          Ohio            10.320152          1170650   \n",
       "4         AR      Arkansas            15.573963           280144   \n",
       "5         OR        Oregon             8.165825           707443   \n",
       "6         TX         Texas            18.107234          6972438   \n",
       "7         ND  North Dakota             4.169715            95235   \n",
       "8         PA  Pennsylvania             9.110052          1102940   \n",
       "9         CT   Connecticut             9.020080           424687   \n",
       "\n",
       "   female_population  total_population  foreign_born  hispanic_or_latino  \\\n",
       "0             506585           1023935        130362              201695   \n",
       "1             175959            352766        101312               24586   \n",
       "2             713072           1408833        213977              103229   \n",
       "3            1248659           2419310        174778              164686   \n",
       "4             296433            576577         61550               77813   \n",
       "5             729066           1436509        185753              201498   \n",
       "6            7138331          14110770       2899610             6311431   \n",
       "7              94255            189490         11492                5234   \n",
       "8            1197619           2300560        287987              387081   \n",
       "9             446332            871019        222850              309992   \n",
       "\n",
       "      white   asian  black_or_african_american  \\\n",
       "0    889798   48801                      21893   \n",
       "1    110508  240978                      11781   \n",
       "2   1050239  151544                     216731   \n",
       "3   1491755   86006                     877366   \n",
       "4    384733   22062                     149608   \n",
       "5   1235819  117279                      72150   \n",
       "6  10508923  924552                    2130242   \n",
       "7    172068    5576                       8177   \n",
       "8   1245618  159308                     851200   \n",
       "9    505674   48311                     231822   \n",
       "\n",
       "   american_indian_and_alaska_native  \n",
       "0                              18746  \n",
       "1                               5592  \n",
       "2                              25242  \n",
       "3                              31808  \n",
       "4                               9381  \n",
       "5                              38597  \n",
       "6                             154497  \n",
       "7                               7142  \n",
       "8                              31849  \n",
       "9                              10729  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_sql = \"\"\"\n",
    "    SELECT first(state_code) as state_code,\n",
    "        first(sw.state) as state, \n",
    "        first(average_temperature) as average_temperature, \n",
    "        CAST(SUM(male_population) / 5 AS int) AS male_population,\n",
    "        CAST(SUM(female_population) / 5 AS int) AS female_population,\n",
    "        CAST(SUM(total_population) / 5 AS int) AS total_population,\n",
    "        CAST(SUM(foreign_born) / 5 AS int) AS foreign_born,\n",
    "        SUM(CASE WHEN race = 'Hispanic or Latino' THEN count ELSE 0 END) AS hispanic_or_latino,\n",
    "        SUM(CASE WHEN race = 'White' THEN count ELSE 0 END) AS white,\n",
    "        SUM(CASE WHEN race = 'Asian' THEN count ELSE 0 END) AS asian,\n",
    "        SUM(CASE WHEN race = 'Black or African-American' THEN count ELSE 0 END) AS black_or_african_american,\n",
    "        SUM(CASE WHEN race = 'American Indian and Alaska Native' THEN count ELSE 0 END) AS american_indian_and_alaska_native\n",
    "    FROM state_weather AS sw\n",
    "    JOIN cities_demographics AS cd ON sw.state = cd.state\n",
    "    GROUP BY sw.state\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "states_table = spark.sql(states_sql)\n",
    "states_table.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country</th>\n",
       "      <th>average_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>384</td>\n",
       "      <td>Chad</td>\n",
       "      <td>27.120466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>529</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>26.610492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>693</td>\n",
       "      <td>Paraguay</td>\n",
       "      <td>23.237968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>158</td>\n",
       "      <td>Russia</td>\n",
       "      <td>-5.521882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>216</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>26.253597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>391</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>27.967375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>130</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>2.386332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>414</td>\n",
       "      <td>Kiribati</td>\n",
       "      <td>26.736865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>603</td>\n",
       "      <td>Guyana</td>\n",
       "      <td>25.930920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>243</td>\n",
       "      <td>Burma</td>\n",
       "      <td>23.706197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country_code   country  average_temperature\n",
       "0           384      Chad            27.120466\n",
       "1           529  Anguilla            26.610492\n",
       "2           693  Paraguay            23.237968\n",
       "3           158    Russia            -5.521882\n",
       "4           216     Yemen            26.253597\n",
       "5           391   Senegal            27.967375\n",
       "6           130    Sweden             2.386332\n",
       "7           414  Kiribati            26.736865\n",
       "8           603    Guyana            25.930920\n",
       "9           243     Burma            23.706197"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_sql = \"\"\"\n",
    "    SELECT country_code,\n",
    "        country_name as country,\n",
    "        average_temperature\n",
    "    FROM country_data AS cd\n",
    "    JOIN country_weather AS cw ON cd.country_name = cw.country\n",
    "\"\"\"\n",
    "\n",
    "countries_table = spark.sql(countries_sql)\n",
    "countries_table.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-26</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-03</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-08-15</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-07-17</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>23</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-05-26</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  day  week  month  year  weekday\n",
       "0  2016-04-25   25    17      4  2016        2\n",
       "1  2016-07-26   26    30      7  2016        3\n",
       "2  2016-05-03    3    18      5  2016        3\n",
       "3  2016-08-31   31    35      8  2016        4\n",
       "4  2016-08-15   15    33      8  2016        2\n",
       "5  2016-07-17   17    28      7  2016        1\n",
       "6  2016-07-03    3    26      7  2016        1\n",
       "7  2016-08-23   23    34      8  2016        3\n",
       "8  2016-05-26   26    21      5  2016        5\n",
       "9  2016-06-02    2    22      6  2016        5"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_sql = \"\"\"\n",
    "    SELECT DISTINCT date,\n",
    "        dayofmonth(date) as day,\n",
    "        weekofyear(date) as week,\n",
    "        month(date) as month,\n",
    "        year(date) as year,\n",
    "        dayofweek(date) as weekday\n",
    "    FROM\n",
    "        (\n",
    "            SELECT arrival_date AS date FROM immigration_data\n",
    "                UNION\n",
    "            SELECT departure_date AS date FROM immigration_data\n",
    "        )\n",
    "\"\"\"\n",
    "\n",
    "times_table = spark.sql(times_sql)\n",
    "times_table.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Creating facts table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citizenship_country</th>\n",
       "      <th>residence_country</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>travel_mode_method</th>\n",
       "      <th>state</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>passenger_age</th>\n",
       "      <th>visa_purpose</th>\n",
       "      <th>passenger_birthyear</th>\n",
       "      <th>gender</th>\n",
       "      <th>visa_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>VA</td>\n",
       "      <td>2016-08-12</td>\n",
       "      <td>46</td>\n",
       "      <td>Business</td>\n",
       "      <td>1970</td>\n",
       "      <td>F</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>MI</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>39</td>\n",
       "      <td>Business</td>\n",
       "      <td>1977</td>\n",
       "      <td>M</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>52</td>\n",
       "      <td>Business</td>\n",
       "      <td>1964</td>\n",
       "      <td>F</td>\n",
       "      <td>E1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>2016-04-26</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>IL</td>\n",
       "      <td>2016-05-04</td>\n",
       "      <td>35</td>\n",
       "      <td>Business</td>\n",
       "      <td>1981</td>\n",
       "      <td>F</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-06-10</td>\n",
       "      <td>50</td>\n",
       "      <td>Business</td>\n",
       "      <td>1966</td>\n",
       "      <td>M</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>AL</td>\n",
       "      <td>2016-05-19</td>\n",
       "      <td>40</td>\n",
       "      <td>Business</td>\n",
       "      <td>1976</td>\n",
       "      <td>M</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>AL</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>55</td>\n",
       "      <td>Business</td>\n",
       "      <td>1961</td>\n",
       "      <td>M</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>AL</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>36</td>\n",
       "      <td>Business</td>\n",
       "      <td>1980</td>\n",
       "      <td>M</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>AL</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>39</td>\n",
       "      <td>Business</td>\n",
       "      <td>1977</td>\n",
       "      <td>M</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>AL</td>\n",
       "      <td>2016-07-21</td>\n",
       "      <td>41</td>\n",
       "      <td>Business</td>\n",
       "      <td>1975</td>\n",
       "      <td>M</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   citizenship_country  residence_country arrival_date travel_mode_method  \\\n",
       "0                  514                514   2016-04-08       Not reported   \n",
       "1                  112                112   2016-04-17       Not reported   \n",
       "2                  268                268   2016-04-17       Not reported   \n",
       "3                  117                117   2016-04-26       Not reported   \n",
       "4                  111                111   2016-04-03       Not reported   \n",
       "5                  260                260   2016-04-22       Not reported   \n",
       "6                  260                260   2016-04-22       Not reported   \n",
       "7                  260                260   2016-04-22       Not reported   \n",
       "8                  260                260   2016-04-22       Not reported   \n",
       "9                  260                260   2016-04-22       Not reported   \n",
       "\n",
       "  state departure_date  passenger_age visa_purpose  passenger_birthyear  \\\n",
       "0    VA     2016-08-12             46     Business                 1970   \n",
       "1    MI     2016-04-24             39     Business                 1977   \n",
       "2    CA     2016-05-27             52     Business                 1964   \n",
       "3    IL     2016-05-04             35     Business                 1981   \n",
       "4    WA     2016-06-10             50     Business                 1966   \n",
       "5    AL     2016-05-19             40     Business                 1976   \n",
       "6    AL     2016-04-23             55     Business                 1961   \n",
       "7    AL     2016-04-28             36     Business                 1980   \n",
       "8    AL     2016-04-28             39     Business                 1977   \n",
       "9    AL     2016-07-21             41     Business                 1975   \n",
       "\n",
       "  gender visa_type  \n",
       "0      F        B1  \n",
       "1      M        WB  \n",
       "2      F        E1  \n",
       "3      F        WB  \n",
       "4      M        WB  \n",
       "5      M        B1  \n",
       "6      M        B1  \n",
       "7      M        B1  \n",
       "8      M        B1  \n",
       "9      M        B1  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigrations_sql = \"\"\"\n",
    "    SELECT cd.country_code as citizenship_country, \n",
    "        cdd.country_code as residence_country, \n",
    "        arrival_date,\n",
    "        tm.travel_mode_method as travel_mode, \n",
    "        state, \n",
    "        departure_date, \n",
    "        passenger_age, \n",
    "        vp.visa_purpose as visa_purpose,\n",
    "        passenger_birthyear,\n",
    "        gender,\n",
    "        id.visa_type\n",
    "    FROM immigration_data AS id\n",
    "    JOIN country_data AS cd ON cd.country_code = id.citizenship_country\n",
    "    JOIN country_data AS cdd ON cdd.country_code = id.residence_country\n",
    "    JOIN state_data AS sd ON sd.state_code = id.state\n",
    "    JOIN visa_purposes AS vp ON vp.visa_code = id.visa_purpose\n",
    "    JOIN travel_modes AS tm ON tm.travel_mode_code = id.travel_mode\n",
    "\"\"\"\n",
    "\n",
    "immigrations_table = spark.sql(immigrations_sql)\n",
    "immigrations_table.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Persisting the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "\n",
    "states_table.write.parquet(\"./tables/states\")\n",
    "countries_table.write.parquet(\"./tables/countries\")\n",
    "times_table.write.parquet(\"./tables/times\")\n",
    "immigrations_table.write.parquet(\"./tables/immigrations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "To check if our dimension tables were created correctly, we will check each of them to see if any field has PK as null, which should not be allowed and should not happen if the pipeline executed correctly.\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Registering created tables in spark\n",
    "\n",
    "states_table.createOrReplaceTempView(\"states\")\n",
    "countries_table.createOrReplaceTempView(\"countries\")\n",
    "times_table.createOrReplaceTempView(\"times\")\n",
    "immigrations_table.createOrReplaceTempView(\"immigrations\")\n",
    "\n",
    "# Perform quality checks here\n",
    "spark.sql(\"SELECT COUNT(*) FROM states WHERE state_code == NULL\").show() # Should be 0\n",
    "spark.sql(\"SELECT COUNT(*) FROM countries WHERE country_code == NULL\").show() # Should be 0\n",
    "spark.sql(\"SELECT COUNT(*) FROM times WHERE date == NULL\").show() # Should be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### States table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This table represents states from United States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Column | Meaning\n",
    "--- | --- \n",
    "state_code | State abbreviation\n",
    "state | State name\n",
    "average_temperature | Average temperature for the state. Data was obtained by aggregating average temperatures from different years.\n",
    "male_population | Male population for state. Was obtained by aggregating data from different cities from the same state.\n",
    "female_population | Female population for state. Was obtained by aggregating data from different cities from the same state.\n",
    "total_population | Total population for state. Was obtained by aggregating data from different cities from the same state.\n",
    "foreign_born | Number of foreigns born at the state. Was obtained by aggregating data from different cities from the same state.\n",
    "hispanic_or_latino | Number of hispanics or latinos at the state. Was obtained through aggregation.\n",
    "white | Number of whites at the state. Was obtained through aggregation.\n",
    "asian | Number of asians at the state. Was obtained through aggregation.\n",
    "black_or_african_american | Number of blacks or african americans at the state. Was obtained through aggregation.\n",
    "american_indian_and_alaska_native | Number of american indians and alaska natives at the state. Was obtained through aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Countries table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This table represents countries from the world and their average temperatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Column | Meaning\n",
    "--- | --- \n",
    "country_code | Code representing the country\n",
    "country | Country name\n",
    "average_temperature | Average temperature for the country. Data was obtained by aggregating average temperatures from different years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Times table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This table represents dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Column | Meaning\n",
    "--- | --- \n",
    "date | A date in the format YYYY-mm-DD.\n",
    "day | Day of the date.\n",
    "week | Week of the month of the date.\n",
    "month | Month of the date.\n",
    "year | Year of the date.\n",
    "weekday | Weekday of the date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Immigrations table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This is our facts table. It contains information about entries and departures at the US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Column | Meaning\n",
    "--- | --- \n",
    "citizenship_country | The country code of the country of citizenship of the immigrant.\n",
    "residence_country | The country code of the country of residence of the immigrant.\n",
    "state | State by which the immigrant arrived. References state_code at states table.\n",
    "arrival_date | Date in which the immigrant arrived.\n",
    "departure_date | Date in which the immigrant departed.\n",
    "travel_mode | Travel mode of the immigrant.\n",
    "visa_purpose | Purpose of the visa of the immigrant, e.g. Pleasure.\n",
    "passenger_age | Passenger age.\n",
    "passenger_birthyear | Passenger birthyear.\n",
    "gender | Passenger gender.\n",
    "visa_type | Visa type, e.g. WB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Example questions and queries to answer them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Get the top 5 states in which passengers resident from Brazil arrive, and their average temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-------------------+\n",
      "|count|     state|average_temperature|\n",
      "+-----+----------+-------------------+\n",
      "|38969|   Florida| 21.501561590688663|\n",
      "|14055|  New York| 7.1836184674575305|\n",
      "| 9206|California| 14.327677288821446|\n",
      "| 5637|    Nevada|  9.814444803695169|\n",
      "| 3042|     Texas|   18.1072339784946|\n",
      "+-----+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(*) as count, s.state, first(s.average_temperature) as average_temperature\n",
    "FROM immigrations as i\n",
    "JOIN countries as c ON c.country_code = i.residence_country\n",
    "JOIN states as s ON s.state_code = i.state\n",
    "WHERE c.country LIKE 'Brazil'\n",
    "GROUP BY s.state\n",
    "ORDER BY count DESC  \n",
    "LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Rationale for tool choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Pandas was used to explore and clean data because it is easy to use and the data sets cleaned with it were not very big, so it was a great tool for the job. To process the data and clean immigration data, spark was used, because it is powerful and easy to scale if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### When should data be updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For our purpose, data should be updated quarterly. It would allow us to not spend much on processing the data, but the travel agency could still get insights and decide on what to sell and to whom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### What to do if data was increased by 100x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since we are already using Spark, we could migrate to an EMR instance on AWS and allow it to scale as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### The data populates a dashboard on a daily basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We could use Apache Airflow to set a daily schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### The database needed to be accessed by 100+ people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We could migrate to Redshift on AWS and scale on the cloud, or could in which ways data is usually queried to create pre aggregations on Cassandra, for example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
